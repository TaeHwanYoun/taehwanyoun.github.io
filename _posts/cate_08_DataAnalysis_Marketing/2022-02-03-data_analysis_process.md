---
layout: post
title: 데이터 분석 리포트 작성 프레임워크(Data Analysis Reporting Framework)
date : 03 Feb 2022
category : ETC
comments : true
---
: 데이터 분석을 하다보면, 연간/분기/특정기간내 서비스 전체 또는 주요 지표들에 대해서 리포팅을 해야하는 상황이 생겨난다. 이에 데이터 분석 리포팅 작성시, 절차 및 이슈들을 정리해보자.
 이때 각자의 문제 상황에 따라서 리포팅 작성 방식은 다를 수 밖에 없기에, 특정 문제를 해결하기 위한 FrameWork라고 보면 좋을 것 같다. 또한 본글은 개인적 경험과 일부 리서치에 기반하였기에, 지속적인 수정 & 보완이 필요하다.  

<br>
# 1. 문제정의 $\star\star\star$
## 1) Why : 리포팅을 왜 하는 것일까? $\star$
 : 리포트를 보는 대상에 따라서, 문제정의 작성 및 리포팅의 이유가 크게 달라진다.
  특정 문제에 국한된 리포트 또는 Daily리포트는 주로 실무자나 중간급에서 빠른 의사결정 및 진행상황을 체크하기 위함이기에 문제정의가 명확하다. <br>

  반면, 리포트 작성의 이유가, 전반적인 서비스 평가 및 서비스 지속 인사이트 추출이라는 모호한 경우가 있다. 주로 중장기간의 서비스 전체 또는 KPI 2,3개 이상의 리포트를 작성하여 상급자에게 리포트를 하는 경우이거나, 아직 데이터로 구체적인 KPI를 잡지 못하여 모니터링 조차 하지 못하는 팀에서 "전체적인 탐색적 분석을 하며 인사이트를 찾고 싶어요"라는 막연한 요청을 하는 경우가 주로 이러하다. <br>

  이런 막연함 속에도 "우리의 서비스가 얼마나 효율적으로 또는 어떤 방향으로 운영되고 있으며", "어떤 문제가 있는지", "분기별로 얼만큼의 성과를 이루었는지" 등의 목표가 존재한다. 추상적인 목표를 아래 분석 항목별로 나눠, 구체화 시키는 작업이 필요하다.


<br>
### 2) What : 무엇을 분석할 것인가? $\star$
 : 커머스 서비스 가정하에 탐색적 분석을 진행하기 위하여, 고객 여정별 분석 항목을 정리해보자.

<center>
<img src = '/assets/DataAnalysis_Marketing/report_1.png' width = '100%'>
</center>  

### (1) 유입 (Acqusition)
    - 앱설치자수 (total / daily)

### (2) 유입 채널 (Attribution)
    - 채널별 앱설치자수(유입자수) (total / daily)
    - 채널별 유입자 *KPI 전환율 (KPI : 회원가입 / 구매 / ETC)
    - 채널별 Fraud / Bounce 유저수 (total / daily)

### (3) 활성화 (Activation)
    - 회원가입자수 (total / monthly / weekly / daily)
    - 회원가입 전환율 (total / monthly / weekly / daily)

### (4) 유지 (Retention)
    - 접속 빈도 : DAU / WAU / MAU
    - 접속 빈도 : 평균 접속주기  
    - 사용 시간 : 세션당 평균 사용 시간 (집단별 / daily)
    - 퍼널 분석 : 설치 > 가입 > 상품 조회 > 상품 구매 > 재구매
                (기간별 / 집단별 비교)

### (5) 참여 & 커머스 (Engagement & Commerce)
    - 참여 : 이벤트 / 공유 조회
    - 커머스 : 상세페이지 조회 & 조회자수  
    - 커머스 : 구매 & 구매자수 (total / monthly / weekly / daily)
    - 커머스 : 재구매 & 재구매율
    - 커머스 : 조회 & 구매 상품 Top 10
    - 커머스 : 구매 전환율 (사용자 그룹별 / 기간별 / 상품별)
    - 커머스 : 구매 금액 / 인당 평균 구매액
    - 커머스 : Pair 분석

### (6) 이탈 (Churn)
    - 최근 7/14/28일 이탈율 (동기간 대비 / 집단별 / 일별)
    - Bounce / Farud  유저수 / 비율

### (7) 도달 (Reachability)
    - 메시지 퍼널 : 발송자 > 오픈자수 > 오픈자 중 구매자
    - 메시지 성과 분석 : 시간대별 접속자수 / 구매자수 추이 + 메시지 발송 시간 표기

### + 인구통계 (Demographic)
    - 전체 유저 : 성별 / 연령 분포
    - 사용자 그룹별(일반 / VIP 등등) : 성별 & 연령 분포
    - 사용자 속성 정보(등급 / 설문 결과 등등)



<br>
### How : 어떻게 분석할 것인가?
 : 위 에서 어떤 항목을 분석할지 선택하더라도, 단일 지표만을 가지고 해당 지표를 긍정적으로 해석해야할지 부정적으로 해석해야할지 판단하기 쉽지 않다. 때문에 타겟 지표를 비교 할 수 있는 비교 집단을 함께 설계하는 것이 중요하다.

    ex) 메시지 성과 분석
    - 분석 집단 : 메시지 발신 후 전환율
    - 비교 집단 : 메시지 발신 전 전환율

<br>  
# 2. 데이터 수집
 : 분석에 필요한 데이터를 수집하는 과정으로, 사전에 협의된 분석 기간의 데이터를 추출한다. 이 단계에서는 데이터의 수집 뿐아니라, 적합성, 커스텀 변수등을 확인한다.

#### 데이터 퀄리티
  - 데이터 누락 확인
#### 데이터 기간
  - 분석 데이터 기간 확인
#### 분석 기준
  - 사용자 기준 데이터
  - 기기 기준 데이터
#### Key, Value, Param 정의
  - 매출, 카테고리 KPI 변수명 등을 사전에 정의

<br>
# 3. 데이터 전처리
 : 수집된 데이터의 결측치, 중복값, 타입오류 등의 이슈를 사전에 체크해준다. 다만 로그데이터를 분석하는 경우, 이상치 제거는 평균의 왜곡 등을 방지하기 위해서 필요하지만, 경우에 따라서 DB값과 차이를 생성하므로, 제거 여부 논의 후 판단해야하는 상황이 생긴다. 주요 전처리 이슈들은 아래와 같다.

#### 1) 데이터셋 확인 단일
  - 상품의 중복 카테고리 이슈 [ex. 상품 1개, 카테고리 2개]
  - 데이터 타입 이슈 [ex. 금액 Value : str type으로 수집됨]
#### 2) 결측값 처리
  - 삭제
  - 대체 (평균, 최빈값, 중간값)
  - 예측값 대체
#### 3) 이상치 처리
  - 단순 삭제
    리포트 경우 삭제가 어렵기에, Scaling으로 편향된 이상치를 조정
  - 대체
  - 변수화
  ex. 특정 고객의 구매금액이 비정상적으로 높음
#### 4) Feature Engineering
  - Scaling
  : 변수의 단위가 너무 크거나 편향 될 경우, 변수간 관계가 잘 드러나지 않기에, Log 또는 SqureRoot등을 취해 스케일 조정
  - Binning
  : 연령, 금액 등 연속형 변수를 범주형 변수로 변경
  -

  * [데이터 전처리에 대한 모든 것 - DODOMIRA](http://www.dodomira.com/2016/10/20/how_to_eda/)
  * [데이터 전처리 필요성 및 - 나는야 데이터사이언티스트](https://rk1993.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC)

  - 모듈화 개발
    - Module_1 : 사용자 그룹 생성
    - Module_2 : 지표 분석
